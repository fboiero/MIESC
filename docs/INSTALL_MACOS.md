# InstalaciÃ³n de Ollama en macOS

## GuÃ­a RÃ¡pida (5 minutos)

### OpciÃ³n 1: Instalador .dmg (Recomendado)

1. **Descargar el instalador**
   ```
   Visita: https://ollama.ai/download
   Descarga: Ollama-darwin.dmg
   ```

2. **Instalar**
   - Abre el archivo .dmg descargado
   - Arrastra Ollama a la carpeta Applications
   - Abre Ollama desde Applications

3. **Verificar instalaciÃ³n**
   ```bash
   ollama --version
   ```

4. **Descargar modelo recomendado**
   ```bash
   ollama pull codellama:13b
   ```

---

### OpciÃ³n 2: Homebrew

Si tienes Homebrew instalado:

```bash
# Instalar Ollama
brew install ollama

# Iniciar servicio
brew services start ollama

# Verificar
ollama --version

# Descargar modelo
ollama pull codellama:13b
```

---

### OpciÃ³n 3: Script de instalaciÃ³n

```bash
# Descargar e instalar
curl -fsSL https://ollama.ai/install.sh | sh

# Verificar
ollama --version

# Descargar modelo
ollama pull codellama:13b
```

---

## Modelos Recomendados

### Desarrollo RÃ¡pido
```bash
ollama pull codellama:7b
# TamaÃ±o: 3.8GB
# Tiempo: ~30s por anÃ¡lisis
```

### Uso General (Recomendado)
```bash
ollama pull codellama:13b
# TamaÃ±o: 7.4GB
# Tiempo: ~60s por anÃ¡lisis
```

### MÃ¡xima Calidad
```bash
ollama pull deepseek-coder:33b
# TamaÃ±o: 19GB
# Tiempo: ~120s por anÃ¡lisis
```

---

## Verificar InstalaciÃ³n

```bash
# 1. Verificar que Ollama estÃ¡ instalado
which ollama
# Debe mostrar: /usr/local/bin/ollama (o similar)

# 2. Verificar que Ollama estÃ¡ corriendo
ollama list
# Debe mostrar los modelos instalados

# 3. Probar un modelo
ollama run codellama:13b "Hello"
# Debe responder con texto generado
```

---

## Ejecutar Test de MIESC

Una vez instalado Ollama:

```bash
# 1. Instalar dependencias Python
pip install -r requirements_agents.txt

# 2. Ejecutar test interactivo
python scripts/test_ollama_crewai.py
```

El test ahora debe pasar todos los checks:
```
System Requirements
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Requirement    â”ƒ Status     â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ Python 3.8+    â”‚ âœ“ PASSED   â”‚
â”‚ Ollama         â”‚ âœ“ PASSED   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Uso con MIESC

### AnÃ¡lisis BÃ¡sico
```bash
python main_ai.py examples/reentrancy.sol test --use-ollama
```

### AnÃ¡lisis Completo
```bash
python main_ai.py examples/reentrancy.sol audit \
  --use-ollama \
  --use-crewai \
  --ollama-model codellama:13b
```

### Modo RÃ¡pido
```bash
python main_ai.py examples/reentrancy.sol test --quick
```

---

## Troubleshooting

### Ollama no se encuentra despuÃ©s de instalar

```bash
# Verificar PATH
echo $PATH

# Agregar Ollama al PATH (si es necesario)
export PATH="/usr/local/bin:$PATH"

# Agregar a ~/.zshrc o ~/.bash_profile
echo 'export PATH="/usr/local/bin:$PATH"' >> ~/.zshrc
source ~/.zshrc
```

### Ollama instalado pero no corre

```bash
# Iniciar Ollama manualmente
open -a Ollama

# O desde terminal
ollama serve &
```

### Modelo no descarga

```bash
# Verificar espacio en disco
df -h

# Verificar conexiÃ³n
ping ollama.ai

# Reintentar descarga
ollama pull codellama:13b
```

### Out of Memory

Si tu Mac tiene < 16GB RAM:

```bash
# Usar modelo mÃ¡s pequeÃ±o
ollama pull codellama:7b

# O el mÃ¡s pequeÃ±o
ollama pull phi:latest
```

---

## ConfiguraciÃ³n Avanzada

### Usar GPU (M1/M2/M3 Macs)

Ollama automÃ¡ticamente usa el GPU en Macs con Apple Silicon:

```bash
# Verificar que estÃ¡ usando GPU
ollama ps
```

### Cambiar UbicaciÃ³n de Modelos

```bash
# Crear variable de entorno
export OLLAMA_MODELS=/path/to/models

# Agregar a ~/.zshrc
echo 'export OLLAMA_MODELS=/path/to/models' >> ~/.zshrc
```

### Limitar Uso de Memoria

```bash
# Limitar a 8GB
export OLLAMA_MAX_VRAM=8192

# Agregar a ~/.zshrc
echo 'export OLLAMA_MAX_VRAM=8192' >> ~/.zshrc
```

---

## DesinstalaciÃ³n

### Si instalaste con Homebrew:
```bash
brew uninstall ollama
brew services stop ollama
```

### Si instalaste con .dmg:
```bash
# Eliminar aplicaciÃ³n
rm -rf /Applications/Ollama.app

# Eliminar modelos
rm -rf ~/.ollama
```

---

## Recursos

- **Sitio oficial**: https://ollama.ai
- **DocumentaciÃ³n**: https://github.com/jmorganca/ollama
- **Modelos disponibles**: https://ollama.ai/library
- **MIESC Docs**: docs/OLLAMA_CREWAI_GUIDE.md

---

## PrÃ³ximos Pasos

1. âœ… Ollama instalado
2. âœ… Modelo descargado
3. â†’ Ejecutar: `python scripts/test_ollama_crewai.py`
4. â†’ Leer: `IMPLEMENTACION_COMPLETA.md`
5. â†’ Usar: `python main_ai.py contract.sol test --use-ollama`

**Â¡Listo para anÃ¡lisis AI gratis y privado!** ðŸŽ‰
